dplyr::count(word, sort = TRUE)
letterCloud(word_counts, word = "2000s", wordSize = 2,color = 'random-dark',backgroundColor = "snow")
word_counts <- song_words_filtered %>%
dplyr::count(word, sort = TRUE)
letterCloud(word_counts, word = "2000s", wordSize = 2,color = 'random-dark',backgroundColor = "snow")
letterCloud(word_counts_2000s, word = "2000s", wordSize = 2,color = 'random-dark',backgroundColor = "snow")
letterCloud(word_counts_2000s, word = "2000s", wordSize = 2,color = 'random-dark',backgroundColor = "snow")
letterCloud(word_counts_2000s, word = "2000s",color = 'random-dark',backgroundColor = "snow")
letterCloud(word_counts_2000s, word = "2000s",color = 'random-dark',backgroundColor = "snow")
letterCloud(word_counts_2000s, word = "2000s",backgroundColor = "snow")
letterCloud(word_counts_2000s, word = "2000s",backgroundColor = "snow")
letterCloud(word_counts_2000s, word = "2000s",backgroundColor = "snow")
log<-system.file("../figs/guitar.png",package="wordcloud2")
wordcloud2(demoFreqC, size = 1,figPath =log)
log
log<-system.file("guitar.png",package="wordcloud2")
wordcloud2(demoFreqC, size = 1,figPath =log)
letterCloud(word_counts_2000s[1:300, ], word = "2000S", wordSize = 2,color = 'random-dark',backgroundColor = "snow")
word_counts_2000s <- song_words_filtered %>%
filter(decades == "2000s") %>%
dplyr::count(word, sort = TRUE)
set.seed(2875)
wordcloud2(word_counts_2000s[1:300, ], size = .5)
letterCloud(word_counts_2000s[1:300, ], word = "2000S", wordSize = 2,color = 'random-dark',backgroundColor = "snow")
word_counts_2000s <- song_words_filtered %>%
filter(decades == "2000s") %>%
dplyr::count(word, sort = TRUE)
set.seed(2875)
wordcloud2(word_counts_2000s[1:300, ], size = .5)
letterCloud(word_counts_2000s[1:300, ], word = "TW", wordSize = 2,color = 'random-dark',backgroundColor = "snow")
letterCloud(word_counts_2000s[1:300, ], word = "TW", wordSize = 2,color = 'random',backgroundColor = "snow")
word_counts_2000s <- song_words_filtered %>%
filter(decades == "2000s") %>%
dplyr::count(word, sort = TRUE)
set.seed(2875)
wordcloud2(word_counts_2000s[1:300, ], size = .5)
letterCloud(word_counts_2000s[1:300, ], word = "2000s", wordSize = 1,color = 'random',backgroundColor = "snow")
library('devtools')
install_github('lchffon/wordcloud2')
library('devtools')
install_github('lchffon/wordcloud2')
install.packages('devtools')
library('devtools')
install_github("lchiffon/wordcloud2")
knitr::opts_chunk$set(echo = TRUE)
library('devtools')
install_github("lchiffon/wordcloud2")
no
no
library('wordcloud2')
letterCloud(word_counts_2000s[1:300, ], word = "2000s", wordSize = 1,color = 'random',backgroundColor = "snow")
install_github("lchiffon/wordcloud2")
install_github("lchiffon/wordcloud2")
library('wordcloud2')
letterCloud(word_counts_2000s[1:300, ], word = "2000s", wordSize = 1,color = 'random',backgroundColor = "snow")
wordcloud2(word_counts_2000s[1:300, ], size = .5)
install.packages('devtools')
knitr::opts_chunk$set(echo = TRUE)
library('devtools')
install_github("lchiffon/wordcloud2")
library('wordcloud2')
letterCloud(word_counts_2000s[1:300, ], word = "2000s", wordSize = 1,color = 'random',backgroundColor = "snow")
letterCloud(word_counts_2000s[1:300, ], word = "2000s", wordSize = 1,color = 'random',backgroundColor = "snow")
install_github("lchiffon/wordcloud2")
install_github("lchiffon/wordcloud2")
cleaned_reviews <- All_data %>%
unnest_tokens(word, stemmedwords) %>%
group_by(id) %>%
dplyr::mutate(position_in_review_0 = 1:n())
nrc = read.table(file = 'https://raw.githubusercontent.com/pseudorational/data/master/nrc_lexicon.txt',header = F,col.names = c('word','sentiment','num'),sep = '\t'); nrc = nrc[nrc$num!=0,]; nrc$num = NULL
#Overall Postive and Negative Emotions
All_data%>%
group_by(id)%>%
unnest_tokens(output = word, input = stemmedwords)%>%
inner_join(nrc)%>%
group_by(sentiment)%>%
filter(sentiment %in% c('positive','negative'))%>%
count()%>%
ggplot(aes(x=sentiment,y=n,fill=sentiment))+geom_col()+theme_economist()+guides(fill=F)+
ggtitle("Positive and Negative Emotion overall") +
theme(plot.title = element_text(hjust = 0.5),
legend.title = element_blank(),
panel.grid.minor = element_blank()) +
coord_flip()
All_data%>%
group_by(id)%>%
unnest_tokens(output = word, input = stemmedwords)%>%
inner_join(nrc)%>%
group_by(sentiment)%>%
filter(sentiment %in% c('positive','negative'))%>%
count()%>%
ggplot(aes(x=sentiment,y=n,fill=sentiment))+geom_col()+theme_economist()+guides(fill=F)+
ggtitle("Positive and Negative Emotion overall") +
theme(plot.title = element_text(hjust = 0.5),
legend.title = element_blank(),
panel.grid.minor = element_blank()) +
coord_flip()
knitr::opts_chunk$set(echo = TRUE)
nrc = read.table(file = 'https://raw.githubusercontent.com/pseudorational/data/master/nrc_lexicon.txt',header = F,col.names = c('word','sentiment','num'),sep = '\t'); nrc = nrc[nrc$num!=0,]; nrc$num = NULL
#head(hash_sentiment_nrc)
dt_lyrics%>%
group_by(id)%>%
unnest_tokens(output = word, input = stemmedwords)%>%
inner_join(nrc)%>%
group_by(sentiment)%>%
filter(sentiment %in% c('positive','negative'))%>%
count()%>%
ggplot(aes(x=sentiment,y=n,fill=sentiment))+geom_col()+theme_economist()+guides(fill=F)+
coord_flip()
packages.used=c("tm", "data.table", "qdap",
"stringr", "tidytext", "tidyverse",
"DT", "lexicon", "ggthemes",
"wordcloud", "sqldf")
library(tm)
library(data.table)
library(tidytext)
library(tidyverse)
library(DT)
library(stringr)
library(qdap)
library(lexicon)
library(ggthemes)
library(wordcloud)
library(sqldf)
# load Processed lyrics data
load('../output/cleaned_lyrics.RData')
nrc = read.table(file = 'https://raw.githubusercontent.com/pseudorational/data/master/nrc_lexicon.txt',header = F,col.names = c('word','sentiment','num'),sep = '\t'); nrc = nrc[nrc$num!=0,]; nrc$num = NULL
#head(hash_sentiment_nrc)
dt_lyrics%>%
group_by(id)%>%
unnest_tokens(output = word, input = stemmedwords)%>%
inner_join(nrc)%>%
group_by(sentiment)%>%
filter(sentiment %in% c('positive','negative'))%>%
count()%>%
ggplot(aes(x=sentiment,y=n,fill=sentiment))+geom_col()+theme_economist()+guides(fill=F)+
coord_flip()
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("dplyr","textdata","ggplot2","gridExtra","tidytext","wordcloud2","knitr","kableExtra","formattable","stringr","tm","igraph","tidyverse","ggraph","rsconnect","DT","wordcloud","scales","cowplot","reshape2")
# 1. check required packages
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# 2.install lacked packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# 3.load all packages
library(dplyr) #data manipulation
library(textdata)
library(ggplot2) #visualizations
library(gridExtra) #viewing multiple plots together
library(tidytext) #text mining
library(wordcloud2) #creative visualizations
library(knitr) # for dynamic reporting
library(kableExtra) # create a nicely formated HTML table
library(formattable) # for the color_tile function
library(stringr)
library(tm)
library(igraph)
library(tidyverse)
library(ggraph)
library(rsconnect)
library(DT)
library(wordcloud)
library(scales)
library(cowplot)
library(reshape2)
library(data.table)
library(lexicon)
library(ggthemes)
#loading processed lyrics data
load('../output/processed_lyrics.RData')
artists = read_csv('../data/artists.csv')
names(artists) = c("artist", "intro", "formed", "members", "origin")
All_data = dt_lyrics %>%
left_join(artists, by = "artist")
#structure of the lyrics
str(All_data[1, ])
song_number<-table(All_data$year)
plot(song_number,xlim=c(1970,2016),type="line")
#Creating buckets for decades
All_data <- All_data %>%
mutate(decades =
ifelse(year %in% 1970:1979, "1970s",
ifelse(year %in% 1980:1989, "1980s",
ifelse(year %in% 1990:1999, "1990s",
ifelse(year %in% 2000:2009, "2000s",
ifelse(year %in% 2010:2020, "2010s",
"NA"))))))
library(magrittr)
All_data %>%
filter(decades != "NA",  genre != "Not Available") %>%
dplyr::group_by(decades, genre) %>%
dplyr::summarise(song_num  = n()) %>%
ggplot() +
geom_bar(aes(x = decades, y = song_num,
fill = genre), stat = "identity")  +
theme(plot.title = element_text(hjust = 0.5),
legend.title = element_blank(),
panel.grid.minor = element_blank()) +
ggtitle("Different genre of Songs number by decades") +
labs(x = NULL, y = "Songs number")
All_data %>%
filter(decades == "2000s",  genre != "Not Available") %>%
dplyr::group_by(decades, genre) %>%
dplyr::summarise(song_num  = n()) %>%
ggplot() +
geom_bar(aes(x = decades, y = song_num,
fill = genre), stat = "identity")  +
theme(plot.title = element_text(hjust = 0.5),
legend.title = element_blank(),
panel.grid.minor = element_blank()) +
ggtitle("Genre distribution of Songs number in 2000s") +
labs(x = NULL, y = "Songs number")+
coord_polar("y", start=0)
song_words_filtered = All_data %>%
unnest_tokens(word, stemmedwords) %>%
anti_join(stop_words) %>%
distinct() %>%
filter(nchar(word) > 3)
song_words_filtered %>%
filter(decades == "2000s") %>%
dplyr::count(word, sort = TRUE) %>%
top_n(10) %>%
ungroup() %>%
mutate(word = reorder(word, n)) %>%
ggplot() +
geom_col(aes(word, n), fill = "blue") +
theme(legend.position = "none",
plot.title = element_text(hjust = 0.5),
panel.grid.major = element_blank()) +
xlab("") +
ylab("Song Count") +
ggtitle("Most popular lyrics in 2000s") +
coord_flip()
word_counts_2000s <- song_words_filtered %>%
filter(decades == "2000s") %>%
dplyr::count(word, sort = TRUE)
set.seed(2875)
wordcloud2(word_counts_2000s[1:300, ], size = .5)
popular_words <- song_words_filtered %>%
filter(decades == "2000s",genre != "Not Available", genre != "Other") %>%
group_by(genre) %>%
dplyr::count(word, genre, sort = TRUE) %>%
slice(seq_len(8)) %>%
ungroup() %>%
arrange(genre,n) %>%
dplyr::mutate(row = row_number())
popular_words %>%
ggplot(aes(row, n, fill = genre)) +
geom_col(show.legend = NULL) +
labs(x = NULL, y = "Song Count") +
ggtitle("2000s Popular Words by Genre") +
theme(plot.title = element_text(hjust = 0.5),
legend.title = element_blank(),
panel.grid.minor = element_blank()) +
facet_wrap(~genre, scales = "free") +
scale_x_continuous(  # This handles replacement of row
breaks = popular_words$row, # notice need to reuse data frame
labels = popular_words$word) +
coord_flip()
nrc = read.table(file = 'https://raw.githubusercontent.com/pseudorational/data/master/nrc_lexicon.txt',header = F,col.names = c('word','sentiment','num'),sep = '\t'); nrc = nrc[nrc$num!=0,]; nrc$num = NULL
#Overall Postive and Negative Emotions
All_data%>%
group_by(id)%>%
unnest_tokens(output = word, input = stemmedwords)%>%
inner_join(nrc)%>%
group_by(sentiment)%>%
filter(sentiment %in% c('positive','negative'))%>%
count()%>%
ggplot(aes(x=sentiment,y=n,fill=sentiment))+geom_col()+theme_economist()+guides(fill=F)+
ggtitle("Positive and Negative Emotion overall") +
theme(plot.title = element_text(hjust = 0.5),
legend.title = element_blank(),
panel.grid.minor = element_blank()) +
coord_flip()
#2000s Postive and Negative Emotions
All_data%>%
filter(decades == "2000s") %>%
group_by(id)%>%
unnest_tokens(output = word, input = stemmedwords)%>%
inner_join(nrc)%>%
group_by(sentiment)%>%
filter(sentiment %in% c('positive','negative'))%>%
count()%>%
ggplot(aes(x=sentiment,y=n,fill=sentiment))+geom_col()+theme_economist()+guides(fill=F)+
ggtitle("Positive and Negative Emotion in 2000s") +
theme(plot.title = element_text(hjust = 0.5),
legend.title = element_blank(),
panel.grid.minor = element_blank()) +
coord_flip()
wordcloudData =
All_data%>%
group_by(id)%>%
unnest_tokens(output=word,input=stemmedwords)%>%
inner_join(nrc)%>%
ungroup()%>%
count(sentiment,word,sort=T)%>%
spread(key=sentiment,value = n,fill=0)%>%
data.frame()
rownames(wordcloudData) = wordcloudData[,'word']
wordcloudData = wordcloudData[,c('positive','negative')]
comparison.cloud(term.matrix = wordcloudData,scale = c(1,0.5),max.words = 250, rot.per=0)
cleaned_reviews <- All_data %>%
unnest_tokens(word, stemmedwords) %>%
group_by(id) %>%
dplyr::mutate(position_in_review_0 = 1:n())
cleaned_reviews %>%
inner_join(get_sentiments("nrc"), by = "word") %>%
dplyr::count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0, fun.aggregate = length) %>%
comparison.cloud(max.words = 200, title.size = 1, scale=c(0.5,1))
#this chunk may take more than 10 mins, be patient please.
sentiment.df<-NULL
emotions_dt <- All_data %>%
filter(decades == "2000s",genre == "Pop")
for(i in 1:nrow(emotions_dt)){
sentences <- get_sentences(emotions_dt$stemmedwords[i])
sentences <- sentences[[1]]
emotions <- get_nrc_sentiment(sentences)
word.count<-word_count(sentences)
emotions<-1/(word.count+0.01) * as.matrix(emotions)
sentiment.df=rbind(sentiment.df,
cbind(dt_lyrics[i,c('id','song','genre')],
sentences=as.character(sentences),
word.count,
emotions
)
)
}
#this chunk may take more than 10 mins, be patient please.
library(sentimentr)
sentiment.df<-NULL
emotions_dt <- All_data %>%
filter(decades == "2000s",genre == "Pop")
for(i in 1:nrow(emotions_dt)){
sentences <- get_sentences(emotions_dt$stemmedwords[i])
sentences <- sentences[[1]]
emotions <- get_nrc_sentiment(sentences)
word.count<-word_count(sentences)
emotions<-1/(word.count+0.01) * as.matrix(emotions)
sentiment.df=rbind(sentiment.df,
cbind(dt_lyrics[i,c('id','song','genre')],
sentences=as.character(sentences),
word.count,
emotions
)
)
}
#this chunk may take more than 10 mins, be patient please.
library(sentimentr)
sentiment.df<-NULL
emotions_dt <- All_data %>%
filter(decades == "2000s",genre == "Pop")
for(i in 1:nrow(emotions_dt)){
sentences <- get_sentences(emotions_dt$stemmedwords[i])
sentences <- sentences[[1]]
emotions <- get_nrc_sentiment(sentences)
word.count<-word_count(sentences)
emotions<-1/(word.count+0.01) * as.matrix(emotions)
sentiment.df=rbind(sentiment.df,
cbind(dt_lyrics[i,c('id','song','genre')],
sentences=as.character(sentences),
word.count,
emotions
)
)
}
library(grid)
#this chunk may take more than 10 mins, be patient please.
library(tm)
library(data.table)
library(tidytext)
library(tidyverse)
library(DT)
library(syuzhet)
library(sentimentr)
library(tibble)
library(qdap)
library(ggplot2)
library(wordcloud2)
library(plotly)
library(gridExtra)
library(grid)
sentiment.df<-NULL
emotions_dt <- All_data %>%
filter(decades == "2000s",genre == "Pop")
for(i in 1:nrow(emotions_dt)){
sentences <- get_sentences(emotions_dt$stemmedwords[i])
sentences <- sentences[[1]]
emotions <- get_nrc_sentiment(sentences)
word.count<-word_count(sentences)
emotions<-1/(word.count+0.01) * as.matrix(emotions)
sentiment.df=rbind(sentiment.df,
cbind(dt_lyrics[i,c('id','song','genre')],
sentences=as.character(sentences),
word.count,
emotions
)
)
}
detach("package:qdap", unload = TRUE)
detach("package:qdapDictionaries", unload = TRUE)
detach("package:qdapRegex", unload = TRUE)
detach("package:qdapTools", unload = TRUE)
sentiment.df<-NULL
emotions_dt <- All_data %>%
filter(decades == "2000s",genre == "Pop")
for(i in 1:nrow(emotions_dt)){
sentences <- get_sentences(emotions_dt$stemmedwords[i])
sentences <- sentences[[1]]
emotions <- get_nrc_sentiment(sentences)
word.count<-word_count(sentences)
emotions<-1/(word.count+0.01) * as.matrix(emotions)
sentiment.df=rbind(sentiment.df,
cbind(dt_lyrics[i,c('id','song','genre')],
sentences=as.character(sentences),
word.count,
emotions
)
)
}
#this chunk may take more than 10 mins, be patient please.
sentiment.df<-NULL
emotions_dt <- All_data %>%
filter(decades == "2000s",genre == "Pop")
for(i in 1:nrow(emotions_dt)){
sentences <- get_sentences(emotions_dt$stemmedwords[i])
sentences <- sentences[[1]]
emotions <- get_nrc_sentiment(sentences)
word.count<-word_count(sentences)
emotions<-1/(word.count+0.01) * as.matrix(emotions)
sentiment.df=rbind(sentiment.df,
cbind(dt_lyrics[i,c('id','song','genre')],
sentences=as.character(sentences),
word.count,
emotions
)
)
}
#this chunk may take more than 10 mins, be patient please.
library(syuzhet)
library(sentimentr)
library(tibble)
library(qdap)
sentiment.df<-NULL
emotions_dt <- All_data %>%
filter(decades == "2000s",genre == "Pop")
for(i in 1:nrow(emotions_dt)){
sentences <- get_sentences(emotions_dt$stemmedwords[i])
sentences <- sentences[[1]]
emotions <- get_nrc_sentiment(sentences)
word.count<-word_count(sentences)
emotions<-1/(word.count+0.01) * as.matrix(emotions)
sentiment.df=rbind(sentiment.df,
cbind(dt_lyrics[i,c('id','song','genre')],
sentences=as.character(sentences),
word.count,
emotions
)
)
}
setwd("~/Documents/GitHub/Spring2020-Project1-slwkq/doc")
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("dplyr","textdata","ggplot2","gridExtra","tidytext","wordcloud2","knitr","kableExtra","formattable","stringr","tm","igraph","tidyverse","ggraph","rsconnect","DT","wordcloud","scales","cowplot","reshape2","data.table","lexicon","ggthemes","syuzhet","sentimentr","tibble","qdap")
# 1. check required packages
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# 2.install lacked packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# 3.load all packages
library(dplyr) #data manipulation
library(textdata)
library(ggplot2) #visualizations
library(gridExtra) #viewing multiple plots together
library(tidytext) #text mining
library(wordcloud2) #creative visualizations
library(knitr) # for dynamic reporting
library(kableExtra) # create a nicely formated HTML table
library(formattable) # for the color_tile function
library(stringr)
library(tm)
library(igraph)
library(tidyverse)
library(ggraph)
library(rsconnect)
library(DT)
library(wordcloud)
library(scales)
library(cowplot)
library(reshape2)
library(data.table)
library(lexicon)
library(ggthemes)
library(syuzhet)
library(sentimentr)
library(tibble)
library(qdap)
#loading processed lyrics data
load('../output/processed_lyrics.RData')
artists = read_csv('../data/artists.csv')
names(artists) = c("artist", "intro", "formed", "members", "origin")
All_data = dt_lyrics %>%
left_join(artists, by = "artist")
#structure of the lyrics
str(All_data[1, ])
song_number<-table(All_data$year)
plot(song_number,xlim=c(1970,2016),type="line")
